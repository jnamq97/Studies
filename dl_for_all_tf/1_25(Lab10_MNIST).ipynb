{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095a489f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6463 - accuracy: 0.8359\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.3493 - accuracy: 0.9050\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.3107 - accuracy: 0.9143\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.2929 - accuracy: 0.9184\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.2826 - accuracy: 0.9210\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.2749 - accuracy: 0.9233\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.2698 - accuracy: 0.9249\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 1s 983us/step - loss: 0.2654 - accuracy: 0.9261\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 1s 947us/step - loss: 0.2623 - accuracy: 0.9272\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 1s 967us/step - loss: 0.2591 - accuracy: 0.9284\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.2570 - accuracy: 0.9291\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.2547 - accuracy: 0.9296\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 1s 995us/step - loss: 0.2529 - accuracy: 0.9298\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 1s 964us/step - loss: 0.2510 - accuracy: 0.9307\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.2502 - accuracy: 0.9309\n",
      "Prediction : \n",
      " [[1.8128216e-06 9.2430378e-12 5.1112729e-06 ... 9.9435294e-01\n",
      "  1.5647656e-05 3.3812446e-04]\n",
      " [2.8324765e-04 2.4135970e-06 9.8905259e-01 ... 1.8887481e-17\n",
      "  7.4179261e-05 6.4333169e-14]\n",
      " [1.5008743e-06 9.7636479e-01 1.2890867e-02 ... 9.8147464e-04\n",
      "  3.7506439e-03 2.9119247e-04]\n",
      " ...\n",
      " [5.8961134e-09 6.0559548e-09 4.2863267e-06 ... 1.5148107e-03\n",
      "  5.7191593e-03 1.7244330e-02]\n",
      " [9.4238089e-08 1.8285596e-07 1.2733740e-07 ... 8.1075008e-08\n",
      "  5.4871184e-03 8.7995346e-08]\n",
      " [5.0674646e-07 1.2449900e-14 3.6735786e-05 ... 8.9255128e-13\n",
      "  3.7775440e-08 4.9825758e-11]]\n",
      "1875/1875 [==============================] - 1s 670us/step - loss: 0.2441 - accuracy: 0.9335\n",
      "Accuracy :  0.9334999918937683\n"
     ]
    }
   ],
   "source": [
    "#10-1 mnist softmax\n",
    "import tensorflow as tf\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 10\n",
    "\n",
    "(x_train,y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "print(x_train.shape)\n",
    "\n",
    "#change data shape(한줄로)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])\n",
    "\n",
    "#change result to one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=10, input_dim=784, activation='softmax'))\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "history = tf.model.fit(x_train,y_train, batch_size=batch_size, epochs=training_epochs)\n",
    "\n",
    "predictions = tf.model.predict(x_test)\n",
    "print(\"Prediction : \\n\", predictions)\n",
    "score = tf.model.evaluate(x_train, y_train)\n",
    "print(\"Accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bd6ed51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "600/600 [==============================] - 2s 2ms/step - loss: 2.2440 - accuracy: 0.8956\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.4067 - accuracy: 0.9445\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2612 - accuracy: 0.9574\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1806 - accuracy: 0.9664\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1674 - accuracy: 0.9681\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1377 - accuracy: 0.9711\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1098 - accuracy: 0.9759\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1004 - accuracy: 0.9766\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9774\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0823 - accuracy: 0.9796\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0740 - accuracy: 0.9808\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0749 - accuracy: 0.9802\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0804 - accuracy: 0.9799\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9835\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0682 - accuracy: 0.9825\n",
      "index : 6311 actual  y: 2 predicted y: 2\n",
      "index : 6890 actual  y: 4 predicted y: 4\n",
      "index : 663 actual  y: 1 predicted y: 1\n",
      "index : 4242 actual  y: 3 predicted y: 3\n",
      "index : 8376 actual  y: 1 predicted y: 1\n",
      "index : 7961 actual  y: 8 predicted y: 8\n",
      "index : 6634 actual  y: 1 predicted y: 1\n",
      "index : 4969 actual  y: 2 predicted y: 2\n",
      "index : 7808 actual  y: 5 predicted y: 5\n",
      "index : 5866 actual  y: 7 predicted y: 7\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2021 - accuracy: 0.9630\n",
      "loss :  0.20210616290569305\n",
      "accuracy : 0.9629999995231628\n"
     ]
    }
   ],
   "source": [
    "#10-2 mnist nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 10\n",
    "\n",
    "(x_train, y_train), (x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=256, input_dim=784, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, activation='softmax'))\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "tf.model.fit(x_train,y_train, batch_size=batch_size, epochs=training_epochs)\n",
    "\n",
    "#predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test)\n",
    "for x in range(0,10) : \n",
    "    random_index = random.randint(0, x_test.shape[0]-1)\n",
    "    print(\"index :\", random_index, \n",
    "         \"actual  y:\", np.argmax(y_test[random_index]),\n",
    "         \"predicted y:\", np.argmax(y_predicted[random_index])) #argmax로 one_hot 한거 역변환 해주는거\n",
    "    \n",
    "score = tf.model.evaluate(x_test,y_test)\n",
    "print('loss : ', score[0])\n",
    "print('accuracy :', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "558e14e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4512 - accuracy: 0.8955\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2363 - accuracy: 0.9425\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1687 - accuracy: 0.9542\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1549 - accuracy: 0.9582\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1292 - accuracy: 0.9657\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1269 - accuracy: 0.9659\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1166 - accuracy: 0.9705\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1130 - accuracy: 0.9708\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0926 - accuracy: 0.9748\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0908 - accuracy: 0.9763\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0900 - accuracy: 0.9767\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0853 - accuracy: 0.9794\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0788 - accuracy: 0.9808\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0750 - accuracy: 0.9822\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0708 - accuracy: 0.9828\n",
      "index :  2201 actual_y :  4 predicted_y : 4\n",
      "index :  9325 actual_y :  0 predicted_y : 0\n",
      "index :  1033 actual_y :  8 predicted_y : 8\n",
      "index :  4179 actual_y :  1 predicted_y : 1\n",
      "index :  1931 actual_y :  5 predicted_y : 5\n",
      "index :  8117 actual_y :  0 predicted_y : 0\n",
      "index :  7364 actual_y :  2 predicted_y : 2\n",
      "index :  7737 actual_y :  0 predicted_y : 0\n",
      "index :  6219 actual_y :  8 predicted_y : 8\n",
      "index :  3439 actual_y :  0 predicted_y : 0\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9689\n",
      "loss :  0.1880892515182495\n",
      "accuracy : 0.9689000248908997\n"
     ]
    }
   ],
   "source": [
    "#10-3 mnist nn xavier\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 10\n",
    "\n",
    "(x_train, y_train), (x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "# Xavier normal initializer = Glorot normal initializer\n",
    "tf.model.add(tf.keras.layers.Dense(units=256, input_dim=784, activation='relu', kernel_initializer='glorot_normal'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=256, activation='relu', kernel_initializer='glorot_normal'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, activation='softmax', kernel_initializer='glorot_normal'))\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "tf.model.fit(x_train, y_train, epochs=training_epochs)\n",
    "\n",
    "#predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test)\n",
    "for x in range(0,10):\n",
    "    random_index = random.randint(0, x_test.shape[0]-1)\n",
    "    print(\"index : \", random_index,\n",
    "         \"actual_y : \", np.argmax(y_test[random_index]),\n",
    "         \"predicted_y :\", np.argmax(y_predicted[random_index]))\n",
    "\n",
    "score = tf.model.evaluate(x_test,y_test)\n",
    "print('loss : ', score[0])\n",
    "print('accuracy :', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d42d99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,195,018\n",
      "Trainable params: 1,195,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.9600 - accuracy: 0.9054\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1426 - accuracy: 0.9594\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1125 - accuracy: 0.9666\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0882 - accuracy: 0.9737\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0864 - accuracy: 0.9746\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0772 - accuracy: 0.9779\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0696 - accuracy: 0.9803\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0620 - accuracy: 0.9823\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0635 - accuracy: 0.9816\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0588 - accuracy: 0.9828\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0520 - accuracy: 0.9858\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0559 - accuracy: 0.9847\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0475 - accuracy: 0.9877\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0396 - accuracy: 0.9893\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0519 - accuracy: 0.9867\n",
      "index : 926 actual y: 2 predicted y : 2\n",
      "index : 1500 actual y: 7 predicted y : 7\n",
      "index : 1390 actual y: 0 predicted y : 0\n",
      "index : 5915 actual y: 1 predicted y : 1\n",
      "index : 2770 actual y: 3 predicted y : 3\n",
      "index : 5048 actual y: 7 predicted y : 7\n",
      "index : 4121 actual y: 8 predicted y : 8\n",
      "index : 9927 actual y: 4 predicted y : 4\n",
      "index : 3476 actual y: 3 predicted y : 3\n",
      "index : 9941 actual y: 5 predicted y : 5\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9784\n",
      "loss :  0.09780921787023544\n",
      "accuracy : 0.9783999919891357\n"
     ]
    }
   ],
   "source": [
    "# mnist nn deep\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(2)\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, input_dim=784, activation='relu', kernel_initializer='glorot_normal'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, activation='relu', kernel_initializer='glorot_normal'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, activation='relu', kernel_initializer='glorot_normal'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, activation='relu', kernel_initializer='glorot_normal'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, activation='softmax', kernel_initializer='glorot_normal'))\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "tf.model.fit(x_train, y_train, epochs=training_epochs, batch_size=batch_size)\n",
    "\n",
    "#predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test)\n",
    "for x in range (0,10):\n",
    "    random_index = random.randint(0, x_test.shape[0]-1)\n",
    "    print(\"index :\", random_index,\n",
    "         \"actual y:\", np.argmax(y_test[random_index]),\n",
    "         \"predicted y :\", np.argmax(y_predicted[random_index]))\n",
    "\n",
    "score = tf.model.evaluate(x_test,y_test)\n",
    "print('loss : ', score[0])\n",
    "print('accuracy :', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "744e9b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,195,018\n",
      "Trainable params: 1,195,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82105\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 5s 9ms/step - loss: 2.0331 - accuracy: 0.7607\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.3644 - accuracy: 0.8987\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.2764 - accuracy: 0.9242\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.2304 - accuracy: 0.9360\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.2024 - accuracy: 0.9445\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1957 - accuracy: 0.9473\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1855 - accuracy: 0.9506\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1857 - accuracy: 0.9526\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1751 - accuracy: 0.9549\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1765 - accuracy: 0.9557\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1749 - accuracy: 0.9565\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1785 - accuracy: 0.9569\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1698 - accuracy: 0.9590\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1563 - accuracy: 0.9609\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1545 - accuracy: 0.9641\n",
      "index:  3757 actual y:  8 predicted y:  3\n",
      "index:  7304 actual y:  5 predicted y:  5\n",
      "index:  7300 actual y:  7 predicted y:  7\n",
      "index:  6039 actual y:  9 predicted y:  9\n",
      "index:  9429 actual y:  3 predicted y:  3\n",
      "index:  4420 actual y:  5 predicted y:  5\n",
      "index:  5507 actual y:  2 predicted y:  2\n",
      "index:  8809 actual y:  1 predicted y:  1\n",
      "index:  654 actual y:  5 predicted y:  5\n",
      "index:  7302 actual y:  8 predicted y:  8\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1201 - accuracy: 0.9740\n",
      "loss:  0.12010166049003601\n",
      "accuracy 0.9739999771118164\n"
     ]
    }
   ],
   "source": [
    "# 10-4 dropout\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "random.seed(777)  # for reproducibility\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 10\n",
    "drop_rate = 0.3\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "# Glorot normal initializer, also called Xavier normal initializer.\n",
    "# see https://www.tensorflow.org/api_docs/python/tf/initializers\n",
    "\n",
    "tf.model.add(tf.keras.layers.Dense(input_dim=784, units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, kernel_initializer='glorot_normal', activation='softmax'))\n",
    "tf.model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "history = tf.model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)\n",
    "\n",
    "# predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test)\n",
    "for x in range(0, 10):\n",
    "    random_index = random.randint(0, x_test.shape[0]-1)\n",
    "    print(\"index: \", random_index,\n",
    "          \"actual y: \", np.argmax(y_test[random_index]),\n",
    "          \"predicted y: \", np.argmax(y_predicted[random_index]))\n",
    "\n",
    "# evaluate test set\n",
    "evaluation = tf.model.evaluate(x_test, y_test)\n",
    "print('loss: ', evaluation[0])\n",
    "print('accuracy', evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42628384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
